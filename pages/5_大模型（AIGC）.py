import streamlit as st
import os
from utils.load_info import load_info
from langchain_openai import ChatOpenAI
from langchain_deepseek import ChatDeepSeek
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# é¡¹ç›®æ ¹ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
# promptæ–‡ä»¶è·¯å¾„
prompt_root = os.path.join(project_root, 'data/Prompt')

# LangChain é…ç½®
os.environ["LANGCHAIN_TRACING"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "AIGC"
os.environ["LANGCHAIN_API_KEY"] = load_info("keys")["LANGCHAIN_API_KEY"]

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(page_title="AIGC èŠå¤©æœºå™¨äºº", page_icon="ğŸ¤–")

st.sidebar.info( 
    "æ¬¢è¿ä½¿ç”¨ AIGC èŠå¤©æœºå™¨äººï¼\n\n"
)

# è¯»å–promptæ–‡ä»¶
def read_prompt_file(dept):
    with open(os.path.join(prompt_root,f"{dept}.md"), "r") as file:
        return file.read()

st.sidebar.markdown("### åŠ©æ‰‹é…ç½®")
domain = st.sidebar.selectbox("é€‰æ‹©åŠ©æ‰‹é¢†åŸŸ",("é€šç”¨é¢†åŸŸ", "åŒ»ç–—åŠ©æ‰‹", "æ•™è‚²åŠ©æ‰‹", "æ³•å¾‹åŠ©æ‰‹"))

if domain == "åŒ»ç–—åŠ©æ‰‹":
    dept = st.sidebar.selectbox("é€‰æ‹©ç§‘å®¤", ("ç”·ç§‘", "å†…ç§‘", "å¦‡äº§ç§‘", "è‚¿ç˜¤ç§‘", "å„¿ç§‘", "å¤–ç§‘"))
    title = domain + " - " + dept
    # è¯»å–prompt
    system = read_prompt_file(dept)
else:
    title = domain
    system = f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{domain}åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ã€‚"

# æ¨¡å‹åˆ—è¡¨
models = load_info("models").keys()

st.sidebar.markdown("### æ¨¡å‹é…ç½®")
selected_model = st.sidebar.selectbox("é€‰æ‹©å¤§æ¨¡å‹",models)
temperature = st.sidebar.slider("æ¸©åº¦", min_value=0.0, max_value=1.0, value=0.5, step=0.1)
max_tokens = st.sidebar.slider("æœ€å¤§ç”ŸæˆTokenæ•°", min_value=10, max_value=2048, value=512, step=10)

st.sidebar.markdown("### é…ç½®è¯´æ˜")
st.sidebar.info(
    "æ¸©åº¦ï¼šæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜ï¼Œç”Ÿæˆçš„æ–‡æœ¬è¶Šéšæœºã€‚\næœ€å¤§ç”ŸæˆTokenæ•°ï¼šæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„é•¿åº¦ï¼Œå€¼è¶Šé«˜ï¼Œç”Ÿæˆçš„æ–‡æœ¬è¶Šé•¿ã€‚"
)

# è‡ªå®šä¹‰CSSï¼Œç¾åŒ–ç•Œé¢
st.markdown("""
<style>
    .stApp {
        background_color: #f0f2f6;
    }
    .stChatInputContainer > div {
        background-color: white;
    }
    [data-testid="stChatMessageContent"] {
        background-color: #e6e6fa;
        border-radius: 0.5rem;
        padding: 0.75rem;
    }
    [data-testid="stChatMessageContent"][aria-label="assistant message"] {
        background-color: #d1e7dd; /* æµ…ç»¿è‰²èƒŒæ™¯ */
    }
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        border-radius: 0.5rem;
    }
    .stButton>button:hover {
        background-color: #45a049;
    }
    h1 {
        color: #333;
    }
</style>
""", unsafe_allow_html=True)

st.title(f"ğŸ’¬ AIGC {title}")
st.caption(f"[{selected_model}] Powered by AIE-52 G5")

# åˆå§‹åŒ–èŠå¤©è®°å½• (ä½¿ç”¨ session_state)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯AIGC èŠå¤©æœºå™¨äººï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"}
    ]

# æ˜¾ç¤ºèŠå¤©è®°å½•
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# è·å–æ¨¡å‹é…ç½®
model_info = load_info("models")[selected_model]
print(f"æ¨¡å‹é…ç½®: {model_info}")
model_name = model_info["model_name"]
base_url = model_info["base_url"]
api_key = model_info["api_key"]

if selected_model == "DeepSeek-Chat":
    Model = ChatDeepSeek
else:
    Model = ChatOpenAI

# å®šä¹‰æ¨¡å‹
llm = Model(
    model=model_name,
    base_url=base_url,
    api_key=api_key,
    temperature=temperature,
    max_tokens=max_tokens,
    streaming=True
    )

# å®šä¹‰æç¤ºæ¨¡æ¿
prompt_template = ChatPromptTemplate.from_messages([
    ("system", system),
    ("human", "{user_input}")
])

# åˆ›å»ºèŠå¤©é“¾
chain = prompt_template | llm | StrOutputParser()

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # è·å–æœºå™¨äººå›å¤ (æ˜¾ç¤ºåŠ è½½çŠ¶æ€)
    with st.chat_message("assistant"):
        try:
            print("å¼€å§‹å¤„ç†æ¶ˆæ¯...")
            with st.spinner("æ€è€ƒä¸­..."):
                # åˆ›å»ºç©ºç™½å ä½ç¬¦ç”¨äºæµå¼è¾“å‡º
                response_placeholder = st.empty()
                response_content = ""
                print("å¼€å§‹å¤„ç†æ¶ˆæ¯...")
                print(f"å¤„ç†æ¶ˆæ¯: {prompt}")
                # ä½¿ç”¨LangChainå¤„ç†æ¶ˆæ¯å¹¶å®ç°æµå¼è¾“å‡º
                for chunk in chain.stream({"user_input": prompt}):
                    print('å¼€å§‹å¤„ç†æ¶ˆæ¯çš„ç‰‡æ®µ...')
                    # print(chunk.content, end='', flush=True)
                    response_content += chunk
                    response_placeholder.markdown(response_content + "â–Œ")  # æ·»åŠ å…‰æ ‡æ•ˆæœ
                
                # å®Œæˆåæ˜¾ç¤ºæœ€ç»ˆå†…å®¹
                import re
                think_content_match = re.search(r'<think>(.*?)</think>', response_content, re.DOTALL)
                if think_content_match:
                    think_text = think_content_match.group(1).strip()
                    # ç§»é™¤åŸå§‹response_contentä¸­çš„thinkæ ‡ç­¾å†…å®¹
                    response_content_without_think = re.sub(r'<think>.*?</think>', '', response_content, flags=re.DOTALL)
                    st.markdown("\n") # åœ¨</think>æ ‡ç­¾åè¿›è¡Œæ¢è¡Œ
                    with st.expander("ç‚¹å‡»æŸ¥çœ‹æ€è€ƒå†…å®¹"): # è®¾ç½®ç‚¹å‡»å¯ä»¥è¿›è¡Œæ”¶èµ·æ¥
                        st.markdown(think_text)
                    response_placeholder.markdown(response_content_without_think)
                else:
                    response_placeholder.markdown(response_content)

        except Exception as e:
            print(f"Error: {e}")
            response_placeholder.markdown("æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚")
    
    # å°†æœºå™¨äººå›å¤æ·»åŠ åˆ°èŠå¤©è®°å½•
    st.session_state.messages.append({"role": "assistant", "content": response_content})

# æ¸…ç©ºèŠå¤©è®°å½•æŒ‰é’®
if len(st.session_state.messages) > 1:
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = [
            {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯AIGC èŠå¤©æœºå™¨äººï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"}
        ]
        st.rerun()